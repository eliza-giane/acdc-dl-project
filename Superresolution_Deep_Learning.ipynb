{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliza-giane/super-resolution-dl-project/blob/main/Superresolution_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "jDqN0s9cydLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is the ACDC Superresolution Project for Deep Learning at AIT by Eliza Giane, Shirui Li, and Lydia Yang.**\n",
        "\n",
        "\n",
        "This project was prompted by the challenge (found [here](https://www.creatis.insa-lyon.fr/Challenge/acdc/index.html)). The data consists of real anonymized and regulated clinical exams from the University Hospital of Dijon, and is described as follows on the challenge's website:\n",
        "\n",
        "\\\\\n",
        "\n",
        "---\n",
        "\"Our dataset covers several well-defined pathologies with enough cases to (1) properly train machine learning methods and (2) clearly assess the variations of the main physiological parameters obtained from cine-MRI (in particular diastolic volume and ejection fraction).\"\n",
        "\n",
        "\"The dataset is composed of 150 exams (all from different patients) divided into 5 evenly distributed subgroups (4 pathological plus 1 healthy subject groups) as described below. Furthermore, each patient comes with the following additional information : weight, height, as well as the diastolic and systolic phase instants.\"\n",
        "\n",
        "---\n",
        "\\\\\n",
        " The dataset is found [here](https://humanheart-project.creatis.insa-lyon.fr/database/#collection/637218c173e9f0047faa00fb/folder/637218e573e9f0047faa00fc) and the provided code for handling .nii files is found [here](https://www.creatis.insa-lyon.fr/Challenge/acdc/code/metrics_acdc.py).\n",
        "\n",
        "\\\\\n",
        "**Any use of the ACDC database requires the following citation:**\n",
        "\n",
        "O. Bernard, A. Lalande, C. Zotti, F. Cervenansky, et al.\n",
        "\"Deep Learning Techniques for Automatic MRI Cardiac Multi-structures Segmentation and Diagnosis: Is the Problem Solved ?\" in IEEE Transactions on Medical Imaging, vol. 37, no. 11, pp. 2514-2525, Nov. 2018, doi: 10.1109/TMI.2018.2837502"
      ],
      "metadata": {
        "id": "ujxY7RfndU-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y-_wKpK8O1pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba141132-b036-41d8-bed9-91c966198f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import configparser\n",
        "from configparser import ConfigParser\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Acquiring Data**\n",
        "\n",
        "The data is stored in Google Drive for access. We organize data into useful forms for pre-processing."
      ],
      "metadata": {
        "id": "KPGPqHP6UJOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getImageFiles(patient, trainingOrTesting):\n",
        "  \"\"\"\n",
        "  Gets the directory paths in a dictionary of all relevant images\n",
        "  trainingOrTesting = \"training\" or \"testing\"\n",
        "  \"\"\"\n",
        "  fileDic = {}\n",
        "  nonDataList = ['MANDATORY_CITATION.md', 'Info.cfg', patient + \"_4d.nii.gz\"]\n",
        "  directory_path = '/content/drive/MyDrive/Superresolution/database/' + trainingOrTesting\n",
        "  directory_files = os.listdir(directory_path)\n",
        "  for patientFile in directory_files:\n",
        "    fileDic[patientFile] = []\n",
        "    if patientFile in nonDataList:  #filter out the non-image files\n",
        "      continue\n",
        "    directoryPatient = directory_path + \"/\" + str(patientFile)\n",
        "    filesPatient = os.listdir(directoryPatient)\n",
        "    for imageFile in filesPatient:\n",
        "      if imageFile in nonDataList:  #filter out the non-image files\n",
        "        continue\n",
        "      directoryPatientImage = directoryPatient + \"/\" + str(imageFile)\n",
        "      fileDic[patientFile].append(directoryPatientImage)\n",
        "  return fileDic[patient]\n",
        "\n",
        "def getInfoFiles(patient, trainingOrTesting):\n",
        "  \"\"\"\n",
        "  Gets the directory paths in a dictionary of all relevant images\n",
        "  trainingOrTesting = \"training\" or \"testing\"\n",
        "  \"\"\"\n",
        "  fileDic = {}\n",
        "  nonDataList = ['MANDATORY_CITATION.md', 'Info.cfg']\n",
        "  directory_path = '/content/drive/MyDrive/Superresolution/database/' + trainingOrTesting\n",
        "  directory_files = os.listdir(directory_path)\n",
        "  for patientFile in directory_files:\n",
        "    fileDic[patientFile] = []\n",
        "    if patientFile in nonDataList:  #filter out the non-info files\n",
        "      continue\n",
        "    directoryPatient = directory_path + \"/\" + str(patientFile)\n",
        "    filesPatient = os.listdir(directoryPatient)\n",
        "    for imageFile in filesPatient:\n",
        "      if imageFile != 'Info.cfg':  #filter out the non-info files\n",
        "        continue\n",
        "      directoryPatientImage = directoryPatient + \"/\" + str(imageFile)\n",
        "      fileDic[patientFile].append(directoryPatientImage)\n",
        "  return fileDic[patient][0]\n",
        "\n",
        "def patientNames(trainingOrTesting):\n",
        "  \"\"\"Returns a list of patient file names based on specified 'training' or 'testing' data\"\"\"\n",
        "  if trainingOrTesting == 'training':\n",
        "    L = []\n",
        "    for i in range(1, 101):\n",
        "        if i < 10:\n",
        "            patient = \"patient\" + \"00\" + str(i)\n",
        "        elif 10 <= i <= 99:\n",
        "            patient = \"patient\" + \"0\" + str(i)\n",
        "        else:\n",
        "            patient = \"patient\" + str(i)\n",
        "        L.append(patient)\n",
        "    return L\n",
        "  elif trainingOrTesting == 'testing':\n",
        "     return [(\"patient\" + str(i)) for i in range(101, 151)]\n",
        "\n",
        "def getData(trainingOrTesting):\n",
        "  \"\"\"Retrieves data for specified 'testing' or 'training' data\"\"\"\n",
        "  arrayDic = {}\n",
        "  for patient in patientNames(trainingOrTesting):\n",
        "    arrayDic[patient] = []\n",
        "    fileDir = getImageFiles(patient, trainingOrTesting)\n",
        "    for patientDir in fileDir:\n",
        "      img = nib.load(patientDir)\n",
        "      arrayDic[patient].append(img.get_fdata())\n",
        "  return arrayDic\n",
        "\n",
        "def label(trainingOrTesting):\n",
        "    \"\"\"Creates dictionary of labels for patient groups for specified 'training' or 'testing' data\"\"\"\n",
        "    L = patientNames(trainingOrTesting)\n",
        "    patientDic = {}\n",
        "    for patient in L:\n",
        "        infopath = getInfoFiles(patient, trainingOrTesting)\n",
        "        parser = configparser.ConfigParser()\n",
        "        with open(infopath) as stream:\n",
        "            parser.read_string(\"[top]\\n\" + stream.read())\n",
        "        details_dict = dict(parser.items(\"top\"))\n",
        "        patientDic[patient] = details_dict['group']\n",
        "    return patientDic"
      ],
      "metadata": {
        "id": "mfxjX77WPz_J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Processing Data**"
      ],
      "metadata": {
        "id": "LpunfWceqFiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stores a dictionary of testing data for patient and their images in a list of arrays of 4 pictures\n",
        "x_train = getData('training')\n",
        "x_test = getData('testing')\n",
        "# Stores a dictionary of labels for patient groups\n",
        "y_train = label('training')\n",
        "y_test = label('testing')"
      ],
      "metadata": {
        "id": "0SVdwNoRqDd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "a8a3621e-f4fc-4aca-e532-21f3c1389eb4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-936aac5ca1ee>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stores a dictionary of testing data for patient and their images in a list of arrays of 4 pictures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Stores a dictionary of labels for patient groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-ef1be1bef307>\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(trainingOrTesting)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpatient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatientNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingOrTesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0marrayDic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mfileDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetImageFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingOrTesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpatientDir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileDir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatientDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-ef1be1bef307>\u001b[0m in \u001b[0;36mgetImageFiles\u001b[0;34m(patient, trainingOrTesting)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdirectoryPatient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatientFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mfilesPatient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectoryPatient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimageFile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilesPatient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mimageFile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonDataList\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#filter out the non-image files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting training into training and validation data\n",
        "train_ratio  = 0.8\n",
        "train_split  = int(len(x_train)*train_ratio) # index to split the training and validation data\n",
        "x_valid, y_valid = dict(list(x_train.items())[train_split:]), dict(list(y_train.items())[train_split:])\n",
        "x_train, y_train = dict(list(x_train.items())[:train_split]), dict(list(y_train.items())[:train_split])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wxKCcIvkN7w",
        "outputId": "7a918f2b-1c7e-45e1-e6ea-1208025d09e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 100\n",
            "20 20\n",
            "80 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dimensions with first patient\n",
        "dim1_train, dim2_train, dim3_train = x_train['patient001'][0].shape\n",
        "dim1_test, dim2_test, dim3_test = x_test['patient101'][0].shape\n",
        "\n",
        "for patient in x_train.keys():\n",
        "  dim1, dim2, dim3 = x_train[patient][0].shape\n",
        "  if dim1 < dim1_train:\n",
        "    dim1_train = dim1\n",
        "\n",
        "  if dim2 < dim2_train:\n",
        "    dim2_train = dim2\n",
        "\n",
        "  if dim3 < dim3_train:\n",
        "    dim3_train = dim3\n",
        "\n",
        "for patient in x_test.keys():\n",
        "  dim1, dim2, dim3 = x_test[patient][0].shape\n",
        "  if dim1 < dim1_test:\n",
        "    dim1_test = dim1\n",
        "\n",
        "  if dim2 < dim2_test:\n",
        "    dim2_test = dim2\n",
        "\n",
        "  if dim3 < dim3_test:\n",
        "    dim3_test = dim3\n",
        "\n",
        "\n",
        "print(dim1_train, dim2_train, dim3_train)\n",
        "print(dim1_test, dim2_test, dim3_test)"
      ],
      "metadata": {
        "id": "3xY1-kNnsQnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e356b6-cdc1-4656-e024-9648d2306f0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154 154 6\n",
            "154 162 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for patient in x_test.keys():\n",
        "#   for i in range(4):\n",
        "#     print(x_test[patient])\n",
        "#     x_test[patient][i] = x_test[patient][i][0:dim1_test]\n",
        "\n",
        "#     for j in range(len(x_test[patient][i])):\n",
        "#       x_test[patient][i][j] = x_test[patient][i][j][0:dim2_test]\n",
        "\n",
        "#       for k in range(len(x_test[patient][i][j])):\n",
        "#         x_test[patient][i][j][k] = x_test[patient][i][j][k][0:dim3_test]\n",
        "\n",
        "\n",
        "#     # x_test[patient][i][1] = x_test[patient][i][1][0:dim2_test]\n",
        "#     # x_test[patient][i][0] = x_test[patient][i][0][0:dim3_test]\n",
        "\n",
        "\n",
        "\n",
        "# for patient in x_train.keys():\n",
        "#   for i in range(4):\n",
        "#     x_train[patient][i] = x_train[patient][i][0:dim1_train, 0:dim2_train, 0:dim3_train]\n",
        "\n"
      ],
      "metadata": {
        "id": "Myx9qoVhvr0a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(x_train[patient][0])"
      ],
      "metadata": {
        "id": "9TW_Pyy-2jnv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for patient in x_test.keys():\n",
        "#   for i in range(4):\n",
        "#     print(x_test[patient][i].shape)\n",
        "\n",
        "# for patient in x_train.keys():\n",
        "#   for i in range(4):\n",
        "#     print(x_train[patient][i].shape)"
      ],
      "metadata": {
        "id": "0r42DzDXzB_P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import new data\n",
        "reshape images\n",
        "split the training data into training and validation data\n",
        "standardize data\n",
        "convert the dense representation of the classes to one-hot encoding"
      ],
      "metadata": {
        "id": "TsJbSijvPCOt"
      }
    }
  ]
}